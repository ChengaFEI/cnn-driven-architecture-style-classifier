{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "import tensorflow as tf                \n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./dataset-lite-augumented\"\n",
    "class_names = os.listdir(DATASET_DIR)\n",
    "class_names_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "num_classes = len(class_names)\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    dataset = './dataset-lite-augumented/'\n",
    "    output = []\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Loading {}\".format(dataset))\n",
    "    \n",
    "    # Iterate through each folder corresponding to a category\n",
    "    for folder in os.listdir(dataset):\n",
    "        label = class_names_labels[folder]\n",
    "        \n",
    "        # Iterate through each image in our folder\n",
    "        for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "            \n",
    "            # Get the path name of the image\n",
    "            img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "            \n",
    "            # Open and resize the img\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, IMAGE_SIZE) \n",
    "            \n",
    "            # Append the image and its corresponding label to the output\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')   \n",
    "\n",
    "    # Split the dataset into train and validation sets (80% train, 20% validation)\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    output.append((train_images, train_labels))\n",
    "    output.append((val_images, val_labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (val_images, val_labels) = loaded_datasets\n",
    "test_images, test_labels = val_images, val_labels\n",
    "\n",
    "print (\"Number of training examples: {}\".format(train_images.shape[0]))\n",
    "print (\"Number of validation examples: {}\".format(val_images.shape[0]))\n",
    "print (\"Number of testing examples: {}\".format(test_images.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "model_vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# perform PCA on the training features\n",
    "train_features = model_vgg.predict(train_images)\n",
    "val_features = model_vgg.predict(val_images)\n",
    "\n",
    "# Reshape the feature vectors to 1D arrays\n",
    "train_features_1d = train_features.reshape(train_features.shape[0], -1)\n",
    "val_features_1d = val_features.reshape(val_features.shape[0], -1)\n",
    "\n",
    "# Perform PCA on the training features\n",
    "n_components = 2  # Choose the number of components you want\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "train_features_pca = pca.fit_transform(train_features_1d)\n",
    "val_features_pca = pca.transform(val_features_1d)\n",
    "\n",
    "print(\"Original training features shape:\", train_features_1d.shape)\n",
    "print(\"Reduced training features shape:\", train_features_pca.shape)\n",
    "\n",
    "print(\"Original validation features shape:\", val_features_1d.shape)\n",
    "print(\"Reduced validation features shape:\", val_features_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scattered plot of data points in the reduced dimensionality space\n",
    "plt.scatter(train_features_pca[:, 0], train_features_pca[:, 1], c=train_labels, cmap='plasma')\n",
    "plt.legend()\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "n_train, x, y, z = train_features.shape\n",
    "n_test, x, y, z = val_features.shape\n",
    "numFeatures = x * y * z\n",
    "\n",
    "pca = decomposition.PCA(n_components = 2)\n",
    "\n",
    "X = train_features.reshape((n_train, x*y*z))\n",
    "pca.fit(X)\n",
    "\n",
    "C = pca.transform(X) # Repr√©sentation des individus dans les nouveaux axe\n",
    "C1 = C[:,0]\n",
    "C2 = C[:,1]\n",
    "\n",
    "### Figures\n",
    "plt.subplots(figsize=(10,10))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.title(\"PCA Projection\"+str(i))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
